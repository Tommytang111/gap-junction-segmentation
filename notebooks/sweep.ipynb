{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96043e2a",
   "metadata": {},
   "source": [
    "#### Wandb Hyperparameter (Agent) Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "068e301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import sys\n",
    "# Add parent directory to sys.path\n",
    "parent_dir = '/home/tommytang111/gap-junction-segmentation/code/src'\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from utilities import UpBlock, DownBlock, DoubleConv, GenDLoss, FocalLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import AdamW, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchmetrics.classification import BinaryRecall, BinaryPrecision, BinaryF1Score\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm #Change to tqdm.tqdm if not using Jupyter Notebook\n",
    "import copy\n",
    "import wandb\n",
    "#Custom Libraries\n",
    "from resize_image import resize_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350a1fd",
   "metadata": {},
   "source": [
    "#### Set Reproducible Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fe71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 40):\n",
    "    \"\"\"\n",
    "    Set the random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    global GLOBAL_SEED\n",
    "    GLOBAL_SEED = seed\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    #torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def worker_init_fn(worker_id):\n",
    "    \"\"\"\n",
    "    Initialize the worker with a unique seed based on the worker ID.\n",
    "    \"\"\"\n",
    "    seed = GLOBAL_SEED + worker_id\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "seed_everything(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de409952",
   "metadata": {},
   "source": [
    "#### Define Augmentation Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08b07506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom augmentation\n",
    "def get_custom_augmentation():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Affine(scale=(0.9,1.1), rotate=10, translate_percent=0.15, shear = (-5, 5), p=0.9),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.2, p=0.5),\n",
    "        A.GaussNoise(p=0.3),\n",
    "        A.Normalize(mean=0.0, std=1.0),\n",
    "        A.Resize(512, 512),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "def get_custom_augmentation2():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Affine(scale=(0.8,1.2), rotate=360, translate_percent=0.15, shear=(-45, 45), p=0.9),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.GaussNoise(p=0.3),\n",
    "        A.Normalize(mean=0.0, std=1.0),\n",
    "        A.Resize(512, 512),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "# Light augmentation for gap junction segmentation\n",
    "def get_light_augmentation():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Transpose(p=0.5),\n",
    "        A.GaussNoise(p=0.3),\n",
    "        A.Blur(blur_limit=3, p=0.2),\n",
    "        A.Normalize(mean=0.0, std=1.0),  # For grayscale\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "# Medium augmentation\n",
    "def get_medium_augmentation():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Transpose(p=0.5),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.1, \n",
    "            scale_limit=0.2, \n",
    "            rotate_limit=15, \n",
    "            border_mode=cv2.BORDER_CONSTANT, \n",
    "            value=0, \n",
    "            p=0.5\n",
    "        ),\n",
    "        A.ElasticTransform(\n",
    "            alpha=1, \n",
    "            sigma=50, \n",
    "            alpha_affine=50, \n",
    "            border_mode=cv2.BORDER_CONSTANT, \n",
    "            value=0, \n",
    "            p=0.3\n",
    "        ),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "        A.Blur(blur_limit=3, p=0.2),\n",
    "        A.CLAHE(clip_limit=2.0, p=0.3),\n",
    "        A.Normalize(mean=0.0, std=1.0),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "    \n",
    "# Heavy augmentation\n",
    "def get_heavy_augmentation():\n",
    "    return A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Transpose(p=0.5),\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.15, \n",
    "            scale_limit=0.3, \n",
    "            rotate_limit=25, \n",
    "            border_mode=cv2.BORDER_CONSTANT, \n",
    "            value=0, \n",
    "            p=0.6\n",
    "        ),\n",
    "        A.ElasticTransform(\n",
    "            alpha=1, \n",
    "            sigma=50, \n",
    "            alpha_affine=50, \n",
    "            border_mode=cv2.BORDER_CONSTANT, \n",
    "            value=0, \n",
    "            p=0.4\n",
    "        ),\n",
    "        A.GridDistortion(p=0.3),\n",
    "        A.OpticalDistortion(p=0.3),\n",
    "        A.GaussNoise(var_limit=(10.0, 80.0), p=0.4),\n",
    "        A.OneOf([\n",
    "            A.Blur(blur_limit=3),\n",
    "            A.GaussianBlur(blur_limit=3),\n",
    "            A.MedianBlur(blur_limit=3),\n",
    "        ], p=0.3),\n",
    "        A.CLAHE(clip_limit=2.0, p=0.4),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
    "        A.Normalize(mean=0.0, std=1.0),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab624b",
   "metadata": {},
   "source": [
    "#### Make Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "287cb019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class can load any mask as long as the model corresponds to the mask type\n",
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, images, labels, masks=None, augmentation=None, data_size=(512, 512), train=True):\n",
    "        self.image_paths = sorted([os.path.join(images, img) for img in os.listdir(images)])\n",
    "        self.label_paths = sorted([os.path.join(labels, lbl) for lbl in os.listdir(labels)])\n",
    "        self.mask_paths = sorted([os.path.join(masks, mask) for mask in os.listdir(masks)]) if masks else None\n",
    "        self.augmentation = augmentation\n",
    "        self.data_size = data_size\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Read image, label, and mask\n",
    "        image = cv2.imread(self.image_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        label = cv2.imread(self.label_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE) if self.mask_paths else None\n",
    "        \n",
    "        #Apply resizing with padding if image is not expected size and then convert back to ndarray\n",
    "        if (image.shape[0] != self.data_size[0]) or (image.shape[1] != self.data_size[1]): \n",
    "            image = np.array(resize_image(image, self.data_size[0], self.data_size[1], (0,0,0)))\n",
    "            label = np.array(resize_image(label, self.data_size[0], self.data_size[1], (0,0,0)))\n",
    "            if mask is not None:\n",
    "                mask = np.array(resize_image(mask, self.data_size[0], self.data_size[1], (0,0,0)))\n",
    "\n",
    "        #Convert mask/label to binary for model classification\n",
    "        label[label > 0] = 1\n",
    "        if mask is not None:\n",
    "            mask[mask > 0] = 1\n",
    "        \n",
    "        #Apply augmentation if provided\n",
    "        if self.augmentation and self.train:\n",
    "            if mask is not None:\n",
    "                #Use mask in augmentation\n",
    "                augmented = self.augmentation(image=image, mask=label, label=mask)\n",
    "                image = augmented['image']\n",
    "                label = augmented['mask']\n",
    "                mask = augmented['label']\n",
    "            else:\n",
    "                #Without mask\n",
    "                augmented = self.augmentation(image=image, mask=label)\n",
    "                image = augmented['image']\n",
    "                label = augmented['mask']\n",
    "\n",
    "        #Add entity recognition clause later if needed\n",
    "        \n",
    "        # Convert to tensors if not already converted from augmentation\n",
    "        if not torch.is_tensor(image):\n",
    "            image = ToTensor()(image).float()\n",
    "        if not torch.is_tensor(label):\n",
    "            label = torch.from_numpy(label).long()\n",
    "        if mask is not None and not torch.is_tensor(mask):\n",
    "            mask = torch.from_numpy(mask).long()\n",
    "        elif mask is None:\n",
    "            mask = torch.zeros_like(label)\n",
    "\n",
    "        return image, label, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792129f0",
   "metadata": {},
   "source": [
    "#### Set Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0185c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For training with augmentation\n",
    "train_augmentation = get_custom_augmentation()  # Change to get_medium_augmentation() or get_heavy_augmentation() as needed\n",
    "\n",
    "# For validation without augmentation\n",
    "valid_augmentation = A.Compose([\n",
    "    A.Normalize(mean=0.0, std=1.0),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227f47e",
   "metadata": {},
   "source": [
    "#### Initialize and Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6134f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TrainingDataset(\n",
    "    images=\"/home/tommytang111/gap-junction-segmentation/data/sem_adult/SEM_split/s250-259/imgs\",\n",
    "    labels=\"/home/tommytang111/gap-junction-segmentation/data/sem_adult/SEM_split/s250-259/gts\",\n",
    "    augmentation=train_augmentation,\n",
    "    train=True,\n",
    ")\n",
    "\n",
    "valid = TrainingDataset(\n",
    "    images=\"/home/tommytang111/gap-junction-segmentation/data/sem_adult/SEM_split/s200-209/imgs\",\n",
    "    labels=\"/home/tommytang111/gap-junction-segmentation/data/sem_adult/SEM_split/s200-209/gts\",\n",
    "    augmentation=valid_augmentation,\n",
    "    train=False\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=8, shuffle=True, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)\n",
    "valid_dataloader = DataLoader(valid, batch_size=8, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab54b7",
   "metadata": {},
   "source": [
    "#### Initialize model and send to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5b99f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"UNet Architecture\"\"\"\n",
    "    def __init__(self, out_classes=2, up_sample_mode='conv_transpose', three=False, attend=False, residual=False, scale=False, spatial=False, dropout=0, classes=2):\n",
    "        \"\"\"Initialize the UNet model\"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        self.three = three\n",
    "        self.up_sample_mode = up_sample_mode\n",
    "        self.dropout=dropout\n",
    "\n",
    "        # Downsampling Path\n",
    "        self.down_conv1 = DownBlock(1, 64, three=three, spatial=False, residual=residual) # 3 input channels --> 64 output channels\n",
    "        self.down_conv2 = DownBlock(64, 128, three=three, spatial=spatial, dropout=self.dropout, residual=residual) # 64 input channels --> 128 output channels\n",
    "        self.down_conv3 = DownBlock(128, 256, spatial=spatial, dropout=self.dropout, residual=residual) # 128 input channels --> 256 output channels\n",
    "        self.down_conv4 = DownBlock(256, 512, spatial=spatial, dropout=self.dropout, residual=residual) # 256 input channels --> 512 output channels\n",
    "        # Bottleneck\n",
    "        self.double_conv = DoubleConv(512, 1024,spatial=spatial, dropout=self.dropout, residual=residual)\n",
    "        # Upsampling Path\n",
    "        self.up_conv4 = UpBlock(512 + 1024, 512, self.up_sample_mode, dropout=self.dropout, residual=residual) # 512 + 1024 input channels --> 512 output channels\n",
    "        self.up_conv3 = UpBlock(256 + 512, 256, self.up_sample_mode, dropout=self.dropout, residual=residual)\n",
    "        self.up_conv2 = UpBlock(128+ 256, 128, self.up_sample_mode, dropout=self.dropout, residual=residual)\n",
    "        self.up_conv1 = UpBlock(128 + 64, 64, self.up_sample_mode)\n",
    "        # Final Convolution\n",
    "        self.conv_last = nn.Conv2d(64, 1 if classes == 2 else classes, kernel_size=1)\n",
    "        self.attend = attend\n",
    "        if scale:\n",
    "            self.s1, self.s2 = torch.nn.Parameter(torch.ones(1), requires_grad=True), torch.nn.Parameter(torch.ones(1), requires_grad=True) # learn scaling\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the UNet model\n",
    "        x: (16, 1, 512, 512)\n",
    "        \"\"\"\n",
    "        # print(x.shape)\n",
    "        x, skip1_out = self.down_conv1(x) # x: (16, 64, 256, 256), skip1_out: (16, 64, 512, 512) (batch_size, channels, height, width)    \n",
    "        x, skip2_out = self.down_conv2(x) # x: (16, 128, 128, 128), skip2_out: (16, 128, 256, 256)\n",
    "        if self.three: x = x.squeeze(-3)   \n",
    "        x, skip3_out = self.down_conv3(x) # x: (16, 256, 64, 64), skip3_out: (16, 256, 128, 128)\n",
    "        x, skip4_out = self.down_conv4(x) # x: (16, 512, 32, 32), skip4_out: (16, 512, 64, 64)\n",
    "        x = self.double_conv(x) # x: (16, 1024, 32, 32)\n",
    "        x = self.up_conv4(x, skip4_out) # x: (16, 512, 64, 64)\n",
    "        x = self.up_conv3(x, skip3_out) # x: (16, 256, 128, 128)\n",
    "        if self.three: \n",
    "            #attention_mode???\n",
    "            skip1_out = torch.mean(skip1_out, dim=2)\n",
    "            skip2_out = torch.mean(skip2_out, dim=2)\n",
    "        x = self.up_conv2(x, skip2_out) # x: (16, 128, 256, 256)\n",
    "        x = self.up_conv1(x, skip1_out) # x: (16, 64, 512, 512)\n",
    "        x = self.conv_last(x) # x: (16, 1, 512, 512)\n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\")    \n",
    "model = UNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754bd04a",
   "metadata": {},
   "source": [
    "#### Initialize loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83fc8b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = GenDLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da4916e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Send evaluation metrics to device\n",
    "recall = BinaryRecall().to(device)\n",
    "precision = BinaryPrecision().to(device)\n",
    "f1 = BinaryF1Score().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9384064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, recall, precision, f1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    # Reset metrics for each epoch\n",
    "    recall.reset()\n",
    "    precision.reset()\n",
    "    f1.reset()\n",
    "    \n",
    "    for batch, (X, y, _) in tqdm(enumerate(dataloader), total=num_batches, desc=\"Training\", leave=False):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Special handling for BCEWithLogitsLoss\n",
    "        if y.dim() == 3:\n",
    "            y = y.unsqueeze(1).float()\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate metrics after converting predictions to binary\n",
    "        pred_binary = (torch.sigmoid(pred) > 0.5).squeeze(1)\n",
    "        \n",
    "        # Update metrics\n",
    "        if y.dim() == 4 and y.size(1) == 1:\n",
    "            y = y.squeeze(1)  # [B, 1, H, W] -> [B, H, W]\n",
    "        recall.update(pred_binary, y)\n",
    "        precision.update(pred_binary, y)\n",
    "        f1.update(pred_binary, y)\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Compute final metrics per epoch\n",
    "    train_recall = recall.compute().item()\n",
    "    train_precision = precision.compute().item()\n",
    "    train_f1 = f1.compute().item()\n",
    "    train_loss_per_epoch = train_loss / num_batches \n",
    "    \n",
    "    return train_loss_per_epoch, train_recall, train_precision, train_f1\n",
    "\n",
    "def validate(dataloader, model, loss_fn, recall, precision, f1):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    # Reset metrics for each epoch\n",
    "    recall.reset()\n",
    "    precision.reset()\n",
    "    f1.reset()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y, _ in tqdm(dataloader, desc=\"Validation\", leave=False):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            #Special handling for BCEWithLogitsLoss\n",
    "            if y.dim() == 3:\n",
    "                y = y.unsqueeze(1).float()\n",
    "            \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            pred_binary = (torch.sigmoid(pred) > 0.5).squeeze(1)\n",
    "            \n",
    "            # Update metrics\n",
    "            if y.dim() == 4 and y.size(1) == 1:\n",
    "                y = y.squeeze(1)  # [B, 1, H, W] -> [B, H, W]\n",
    "            recall.update(pred_binary, y)\n",
    "            precision.update(pred_binary, y)\n",
    "            f1.update(pred_binary, y)\n",
    "            \n",
    "    # Compute final metrics per epoch\n",
    "    val_recall = recall.compute().item()\n",
    "    val_precision = precision.compute().item()\n",
    "    val_f1 = f1.compute().item()\n",
    "    val_loss_per_epoch = test_loss / num_batches\n",
    "\n",
    "    return val_loss_per_epoch, val_recall, val_precision, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c164024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep():\n",
    "    # Initialize wandb run\n",
    "    wandb.login(key=\"04e003d2c64e518f8033ab016c7a0036545c05f5\")\n",
    "    wandb.init(\n",
    "        project=\"gap-junction-segmentation\",\n",
    "        entity=\"zhen_lab\",\n",
    "        dir=\"/home/tommytang111/gap-junction-segmentation/wandb\"\n",
    "    )\n",
    "    \n",
    "    # Get hyperparameters from wandb config\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Set seeds\n",
    "    seed_everything(42)\n",
    "    \n",
    "    # Get augmentation strategy from config, default to 'medium'\n",
    "    aug_strategy = config.get('augmentation', 'custom2')\n",
    "\n",
    "    if aug_strategy == 'custom1':\n",
    "        train_aug = get_custom_augmentation()\n",
    "    elif aug_strategy == 'custom2':\n",
    "        train_aug = get_custom_augmentation2()\n",
    "\n",
    "    valid_aug = A.Compose([A.Normalize(mean=0.0, std=1.0), ToTensorV2()])\n",
    "\n",
    "    # Initialize datasets with config batch size\n",
    "    train_dataset = TrainingDataset(\n",
    "        images=\"/home/tommytang111/gap-junction-segmentation/data/pilot1/train/imgs\",\n",
    "        labels=\"/home/tommytang111/gap-junction-segmentation/data/pilot1/train/gts\",\n",
    "        augmentation=train_aug,\n",
    "        train=True\n",
    "    )\n",
    "    \n",
    "    valid_dataset = TrainingDataset(\n",
    "        images=\"/home/tommytang111/gap-junction-segmentation/data/pilot1/val/imgs\",\n",
    "        labels=\"/home/tommytang111/gap-junction-segmentation/data/pilot1/val/gts\",\n",
    "        augmentation=valid_aug,\n",
    "        train=False\n",
    "    )\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=4, \n",
    "        pin_memory=True, \n",
    "        worker_init_fn=worker_init_fn\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=4, \n",
    "        pin_memory=True, \n",
    "        worker_init_fn=worker_init_fn\n",
    "    )\n",
    "    \n",
    "    # Initialize model with config dropout\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = UNet(dropout=config.dropout).to(device)\n",
    "    \n",
    "    #Loss function mapping\n",
    "    if config.loss_function == \"GenDLoss\":\n",
    "        loss_fn = GenDLoss()\n",
    "    #elif config.loss_function == \"BCEWithLogitsLoss\":\n",
    "        #loss_fn = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([2.0], device=device))\n",
    "    elif config.loss_function == \"FocalLoss\":\n",
    "        loss_fn = FocalLoss(alpha=torch.Tensor([0.08, 0.92]), device=device)\n",
    "\n",
    "    #Optimizer mapping\n",
    "    if config.optimizer == \"AdamW\":\n",
    "        optimizer = AdamW(model.parameters(), lr=config.learning_rate, weight_decay=1e-4)\n",
    "    elif config.optimizer == \"SGD\":\n",
    "        optimizer = SGD(model.parameters(), lr=config.learning_rate, momentum=0.9, weight_decay=1e-4)\n",
    "    \n",
    "    # Initialize learning rate scheduler\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min', \n",
    "        factor=0.5, \n",
    "        patience=10, \n",
    "        min_lr=1e-6\n",
    "    )\n",
    "    \n",
    "    # Initialize metrics\n",
    "    recall = BinaryRecall().to(device)\n",
    "    precision = BinaryPrecision().to(device)\n",
    "    f1 = BinaryF1Score().to(device)\n",
    "    \n",
    "    # Training loop\n",
    "    torch.cuda.empty_cache()\n",
    "    epochs = 50  # Reduced for sweep\n",
    "    best_f1 = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\")\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_recall, train_precision, train_f1 = train(\n",
    "            train_dataloader, model, loss_fn, optimizer, recall, precision, f1\n",
    "        )\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_recall, val_precision, val_f1 = validate(\n",
    "            valid_dataloader, model, loss_fn, recall, precision, f1\n",
    "        )\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train | Loss: {train_loss:.4f}, Recall: {train_recall:.4f}, Precision: {train_precision:.4f}, F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   | Loss: {val_loss:.4f}, Recall: {val_recall:.4f}, Precision: {val_precision:.4f}, F1: {val_f1:.4f}\")\n",
    "        print(\"-----------------------------\")\n",
    "\n",
    "        # Log best model state\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_epoch = epoch\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            # Save best model for this run\n",
    "            model_path = f\"/home/tommytang111/gap-junction-segmentation/models/sweep_model_{wandb.run.id}.pt\"\n",
    "            \n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_recall\": train_recall,\n",
    "            \"train_precision\": train_precision,\n",
    "            \"train_f1\": train_f1,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_recall\": val_recall,\n",
    "            \"val_precision\": val_precision,\n",
    "            \"val_f1\": val_f1,\n",
    "            \"best_val_f1\": best_f1,\n",
    "            \"best_val_loss\": best_val_loss,\n",
    "            \"best_epoch\": best_epoch,\n",
    "            \"lr\": optimizer.param_groups[0][\"lr\"]\n",
    "        })\n",
    "\n",
    "    print(\"Training Complete!\")\n",
    "    torch.save(best_model_state, model_path)\n",
    "    print(\"Saved PyTorch Model to \", model_path)\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3011fb79",
   "metadata": {},
   "source": [
    "#### **Sweep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb0f2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define sweep configuration\n",
    "sweep_config = {\n",
    "    'method': 'bayes',  # or 'random', 'bayes'\n",
    "    'metric': {\n",
    "        'name': 'val_f1',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "            'values': [0.01, 0.001, 0.0001]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [8]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['AdamW']\n",
    "        },\n",
    "        'loss_function': {\n",
    "            'values': ['GenDLoss']\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0, 0.1]\n",
    "        },\n",
    "        'augmentation': {\n",
    "            'values': ['custom1', 'custom2']\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3542c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"gap-junction-segmentation\")\n",
    "print(f\"Sweep ID: {sweep_id}\")\n",
    "\n",
    "# Start the sweep agent\n",
    "wandb.agent(sweep_id=sweep_id, function=sweep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gap_junction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
