{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzLMHCTHXxF4"
      },
      "source": [
        "# Load CATMAID Gap Junctions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initialize CATMAID Helper Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "zBY4ftapXPPe",
        "outputId": "cb9f55f5-ca9e-4e51-db8a-188885da1b8e"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "sys.path.append(\"../catmaid\")\n",
        "from catmaidhelper import CatmaidHelper\n",
        "\n",
        "pid = 290 #SEM Adult, 301 for dauer1 290 for dauer2, 281 for adult\n",
        "\n",
        "with open(\"/home/tommytang111/gap-junction-segmentation/secrets.txt\") as f:\n",
        "    api_token = f.readlines()[1].strip()\n",
        "url = 'https://zhencatmaid.com/'\n",
        "\n",
        "catmaid = CatmaidHelper(url, api_token)\n",
        "catmaid.set_project(pid)\n",
        "\n",
        "# skeletons = catmaid.get_skeletons()\n",
        "# skeleton_names = catmaid.load_skeleton_names(skeletons)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gap Junctions are a subset of connector objects in CATMAID. \\\n",
        "Getting a GJ Connector gives you the GJ, and the partners as a skeleton. \\\n",
        "Need to make sure relation_name is \"gapjunction_with\" for the connector to extract GJs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Connector endpoint for fetching all connectors in a project\n",
        "connectors = catmaid.fetch(\n",
        "    url = f\"/{pid}/connectors/\",\n",
        "    method = \"post\",\n",
        "    data = {\n",
        "        \"project_id\": pid,\n",
        "    }).json()['connectors']\n",
        "\n",
        "cid = connectors[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Connector endpoint for fetching a specific connector by its ID\n",
        "connector_info = catmaid.fetch(\n",
        "    url = f\"/{pid}/connectors/{cid}/\",\n",
        "    method = \"get\",\n",
        "    data = {\n",
        "        \"project_id\": pid,\n",
        "        \"connector_id\": cid\n",
        "    }).json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'x' in connector_info.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14641/14641 [10:52<00:00, 22.45it/s]\n"
          ]
        }
      ],
      "source": [
        "#Make a dictionary of gap junction connectors and their coordinates\n",
        "#Coordinates are in nm, not voxels, so will need to be converted later\n",
        "gap_junction_dict = {}\n",
        "for connector in tqdm(connectors, total=len(connectors)):\n",
        "    cid = connector[0]\n",
        "    #Get connector info for each connector ID\n",
        "    connector_info = catmaid.fetch(\n",
        "    url = f\"/{pid}/connectors/{cid}/\",\n",
        "    method = \"get\",\n",
        "    data = {\"project_id\": pid, \"connector_id\": cid}).json()\n",
        "    if 'detail' not in connector_info.keys():\n",
        "        if connector_info['partners'][0]['relation_name'] == \"gapjunction_with\" and connector_info['partners'][1]['relation_name'] == \"gapjunction_with\":\n",
        "            gap_junction_dict[cid] = [connector[1:4]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8145"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(gap_junction_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Save gap junction dict as json\n",
        "import json \n",
        "\n",
        "with open(\"/home/tommytang111/gap-junction-segmentation/sem_dauer_2_GJs.json\", \"w\") as f:\n",
        "    json.dump(gap_junction_dict, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert JSON to NPY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Section Shape: (7000, 10500)\n",
            "Prediction Shape: (7000, 10500)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "sys.path.insert(0, '/home/tommytang111/gap-junction-segmentation/code/src')\n",
        "from utils import split_img\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2 \n",
        "\n",
        "#Load points and get dimensions of a section\n",
        "gj_points = pd.read_json(\"/home/tommytang111/gap-junction-segmentation/gj_point_annotations/sem_adult_GJs.json\", orient='index')\n",
        "gj_points.rename(columns={0: \"points\"}, inplace=True)\n",
        "shape = cv2.imread(\"/mnt/e/Tommy/SEM_adult/Predictions/2D/SEM_adult_image_export_s250_pred.png\", cv2.IMREAD_GRAYSCALE).shape\n",
        "print(f\"Section Shape: {cv2.imread('/mnt/e/Tommy/SEM_adult/Sections/SEM_adult_image_export_s250.png', cv2.IMREAD_GRAYSCALE).shape}\")\n",
        "print(f\"Prediction Shape: {shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Get max coordinates in annotations for a particular dataset\n",
        "max_x, max_y, max_z = 0, 0, 0\n",
        "for gj in gj_points['points']:\n",
        "    if gj[0] > max_x:\n",
        "        max_x = gj[0]\n",
        "    if gj[1] > max_y:\n",
        "        max_y = gj[1]\n",
        "    if gj[2] > max_z:\n",
        "        max_z = gj[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72776.2 37034.0 21420.0\n",
            "18194.0 9258.0 714.0\n"
          ]
        }
      ],
      "source": [
        "#See if GJ points dataset dimensions match dataset I'm working with\n",
        "print(max_x, max_y, max_z)  #10500, 7000, 700 something like this shape\n",
        "print(max_x//4, max_y//4, max_z//30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = gj_points.apply(lambda row: (row['points'][0]//4, row['points'][1]//4, row['points'][2]//30), axis=1)\n",
        "split_df=pd.DataFrame()\n",
        "split_df[['x', 'y', 'z']] = pd.DataFrame(test_df.tolist(), index=test_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#DON'T ACTUALLY RUN THIS, WILL GET OOM ERROR. Implementation is in transforms/make_point_volume_from_JSON.py\n",
        "#Create empty_volume\n",
        "test_vol = np.zeros((972, 8328, 9360), dtype=np.uint8)  # Z, Y, X\n",
        "\n",
        "#Populate volume with gap junction points\n",
        "for gj in gj_points['points']:\n",
        "    test_vol[int(gj[2])//50, int(gj[1])//2, int(gj[0])//2] = 255 \n",
        "    \n",
        "#Save volume\n",
        "np.save(\"/home/tommytang111/gap-junction-segmentation/gj_point_annotations/sem_adult_GJs.npy\", test_vol)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### William"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JppoE5EzoKA0",
        "outputId": "619bd7ac-8a0c-4774-fb1f-cd330bfd9c10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4455/4455 [02:50<00:00, 26.12it/s]\n"
          ]
        }
      ],
      "source": [
        "#William's stuff\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import concurrent.futures as futures\n",
        "\n",
        "# Load all connector info\n",
        "\n",
        "col_names = [\"connector_id\",\"x\",\"y\",\"z\"]\n",
        "col_ids = [0,1,2,3]\n",
        "\n",
        "connectors = pd.DataFrame(catmaid.get_connectors()).iloc[:,col_ids]\n",
        "connectors = connectors.rename(columns=dict(zip(col_ids,col_names)))\n",
        "\n",
        "def get_link_info(connector_id):\n",
        "    connector_subtable = []\n",
        "    connector_info = catmaid.get_connector_info(connector_id)\n",
        "    pre = \"\"\n",
        "    pre_node = 0\n",
        "    post = []\n",
        "    post_nodes = []\n",
        "    for partner in connector_info['partners']:\n",
        "        if partner['relation_name'] == 'presynaptic_to':\n",
        "            if partner['confidence'] < 5:\n",
        "                continue\n",
        "            pre = partner['skeleton_id']\n",
        "            pre_node = partner['partner_id']\n",
        "        if partner['relation_name'] == 'postsynaptic_to':\n",
        "            if partner['confidence'] < 5:\n",
        "                continue\n",
        "            post.append(partner['skeleton_id'])\n",
        "            post_nodes.append(partner['partner_id'])\n",
        "    for i in range(len(post)):\n",
        "        connector_subtable.append({\n",
        "            \"connector_id\": connector_info['connector_id'],\n",
        "            \"x\": connector_info['x'],\n",
        "            \"y\": connector_info['y'],\n",
        "            \"z\": connector_info['z'],\n",
        "            \"pre\": pre,\n",
        "            \"pre_node\": pre_node,\n",
        "            \"post\": post[i],\n",
        "            \"post_node\": post_nodes[i]})\n",
        "    return connector_subtable\n",
        "\n",
        "with futures.ThreadPoolExecutor() as executor:\n",
        "    results = list(tqdm(executor.map(get_link_info, connectors['connector_id']), total=len(connectors)))\n",
        "\n",
        "connector_table = [item for sublist in results if sublist for item in sublist]\n",
        "connector_table = pd.DataFrame(connector_table)\n",
        "\n",
        "# only include elements within bounded nodes for each particular skeleton\n",
        "pre_skel_filt = connector_table['pre'].isin(bounded_nodes.keys())\n",
        "connector_table = connector_table[pre_skel_filt]\n",
        "\n",
        "all_bounded_nodes = set()\n",
        "for nodes in bounded_nodes.values():\n",
        "    all_bounded_nodes.update(nodes)\n",
        "\n",
        "connector_table_filt = connector_table[connector_table['pre_node'].isin(all_bounded_nodes)]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gap_junction",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
