{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "891c2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Plot volume\n",
    "import numpy as np\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "pred1 = np.load(\"/Users/tommy/Projects/gap-junction-segmentation/data/volume_block_downsampled8x_5dggwboi.npy\")\n",
    "pred2 = np.load(\"/Users/tommy/Projects/gap-junction-segmentation/data/volume_block_downsampled8x_u4lqcs5g.npy\")\n",
    "pred1 = block_reduce(pred1, block_size=(1,2,2), func=np.max)\n",
    "pred2 = block_reduce(pred2, block_size=(1,2,2), func=np.max)\n",
    "pred1_ = np.transpose(pred1, (2, 1, 0))\n",
    "pred2_ = np.transpose(pred2, (2, 1, 0))\n",
    "#print(np.unique(pred_3d_, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e103dc",
   "metadata": {},
   "source": [
    "#### With Plotly (Currently Broken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from skimage.measure import marching_cubes\n",
    "import plotly.io as pio\n",
    "from PIL import Image\n",
    "import io\n",
    "from scipy.spatial import Delaunay\n",
    "import cv2\n",
    "\n",
    "def simplify_mesh(vertices, faces, reduction_factor=0.5):\n",
    "    \"\"\"Reduce mesh complexity by decimation\"\"\"\n",
    "    # Use PyVista's built-in decimation\n",
    "    import pyvista as pv\n",
    "    mesh = pv.PolyData(vertices, np.column_stack([np.full(len(faces), 3), faces]))\n",
    "    decimated = mesh.decimate(reduction_factor)\n",
    "    new_verts = decimated.points\n",
    "    new_faces = decimated.faces.reshape(-1, 4)[:, 1:4]\n",
    "    return new_verts, new_faces\n",
    "\n",
    "# Function to create rotated frame\n",
    "def create_frame(angle):\n",
    "    # Rotate vertices around Z-axis\n",
    "    cos_a = np.cos(np.radians(angle))\n",
    "    sin_a = np.sin(np.radians(angle))\n",
    "    \n",
    "    # Center the meshes\n",
    "    center1 = verts1.mean(axis=0)\n",
    "    center2 = verts2.mean(axis=0)\n",
    "    \n",
    "    # Apply rotation\n",
    "    v1_centered = verts1 - center1\n",
    "    v1_rot = np.column_stack([\n",
    "        v1_centered[:, 0] * cos_a - v1_centered[:, 1] * sin_a,\n",
    "        v1_centered[:, 0] * sin_a + v1_centered[:, 1] * cos_a,\n",
    "        v1_centered[:, 2]\n",
    "    ]) + center1\n",
    "    \n",
    "    v2_centered = verts2 - center2\n",
    "    v2_rot = np.column_stack([\n",
    "        v2_centered[:, 0] * cos_a - v2_centered[:, 1] * sin_a,\n",
    "        v2_centered[:, 0] * sin_a + v2_centered[:, 1] * cos_a,\n",
    "        v2_centered[:, 2]\n",
    "    ]) + center2\n",
    "    \n",
    "    # Offset second mesh for side-by-side\n",
    "    offset = pred1_.shape[0] + 50\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add first mesh\n",
    "    fig.add_trace(go.Mesh3d(\n",
    "        x=v1_rot[:, 0], y=v1_rot[:, 1], z=v1_rot[:, 2],\n",
    "        i=faces1[:, 0], j=faces1[:, 1], k=faces1[:, 2],\n",
    "        color='cyan',\n",
    "        name='UNet 5dggwboi',\n",
    "        opacity=0.8,\n",
    "        lighting=dict(ambient=0.5, diffuse=0.8, specular=0.2)\n",
    "    ))\n",
    "    \n",
    "    # Add second mesh\n",
    "    fig.add_trace(go.Mesh3d(\n",
    "        x=v2_rot[:, 0] + offset, y=v2_rot[:, 1], z=v2_rot[:, 2],\n",
    "        i=faces2[:, 0], j=faces2[:, 1], k=faces2[:, 2],\n",
    "        color='orange',\n",
    "        name='UNet u4lqcs5g',\n",
    "        opacity=0.8,\n",
    "        lighting=dict(ambient=0.5, diffuse=0.8, specular=0.2)\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            bgcolor='black',\n",
    "            xaxis=dict(visible=False),\n",
    "            yaxis=dict(visible=False),\n",
    "            zaxis=dict(visible=False),\n",
    "            aspectmode='data'\n",
    "        ),\n",
    "        showlegend=True,\n",
    "        width=1920,\n",
    "        height=1080,\n",
    "        paper_bgcolor='black',\n",
    "        font=dict(color='white')\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create mesh from volume\n",
    "verts1, faces1, _, _ = marching_cubes(pred1_, level=127)\n",
    "verts2, faces2, _, _ = marching_cubes(pred2_, level=127)\n",
    "\n",
    "# Simplify before rendering\n",
    "verts1, faces1 = simplify_mesh(verts1, faces1, reduction_factor=0.7)  # Keep 30% of triangles\n",
    "verts2, faces2 = simplify_mesh(verts2, faces2, reduction_factor=0.7)\n",
    "print(f\"Simplified mesh sizes: {len(verts1)} and {len(verts2)} vertices\")\n",
    "\n",
    "# After generating frames as PIL Images\n",
    "output_path = \"/Users/tommy/Projects/gap-junction-segmentation/outputs/predictions_comparison.mp4\"\n",
    "height, width = 1080, 1920\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video = cv2.VideoWriter(output_path, fourcc, 30, (width, height))\n",
    "\n",
    "print(\"Generating frames...\")\n",
    "for i in range(360):\n",
    "    if i % 30 == 0:\n",
    "        print(f\"Frame {i}/360\")\n",
    "    \n",
    "    angle = i\n",
    "    fig = create_frame(angle)\n",
    "    img_bytes = pio.to_image(fig, format='png', width=width, height=height)\n",
    "    img = Image.open(io.BytesIO(img_bytes))\n",
    "    frame = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "    video.write(frame)\n",
    "\n",
    "video.release()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f62ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap into a pyvista UniformGrid\n",
    "grid1 = pv.wrap(pred1_)\n",
    "contour1 = grid1.contour(isosurfaces=[255])\n",
    "grid2 = pv.wrap(pred2_)\n",
    "contour2 = grid2.contour(isosurfaces=[255])\n",
    "\n",
    "# # Volume rendering (interactive)\n",
    "# pv.set_jupyter_backend(\"html\")\n",
    "# p = pv.Plotter(notebook=True)\n",
    "# p.add_mesh(contour1, color=\"#02EBFC\", show_scalar_bar=False)\n",
    "# p.add_mesh(contour2, color=\"#BF35FF\", show_scalar_bar=False)\n",
    "# p.set_background(\"black\")\n",
    "# p.camera_position = \"iso\"\n",
    "# p.enable_eye_dome_lighting()        \n",
    "# p.show_axes()                         \n",
    "# #p.export_html(\"/home/tommytang111/gap-junction-segmentation/html_objects/SEM_Dauer_1_3D.html\")\n",
    "# p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1d5b75",
   "metadata": {},
   "source": [
    "#### Export interactive browser format with multiple subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89624d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9a19dc5a644fa0b4b3c6cf999219ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Widget(value='<iframe src=\"http://localhost:50289/index.html?ui=P_0x12a75de10_1&reconnect=auto\" class=\"pyvista…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contour1: 6014177 points, 12307314 cells\n",
      "contour2: 6444998 points, 13072649 cells\n"
     ]
    }
   ],
   "source": [
    "#Global plot settings\n",
    "pv.set_jupyter_backend(\"client\")\n",
    "pv.global_theme.background = 'black'\n",
    "pv.force_float=False\n",
    "p = pv.Plotter(notebook=True, shape=(1, 2))\n",
    "\n",
    "#Prediction 1\n",
    "p.subplot(0,0)\n",
    "p.add_mesh(contour1, color=\"#02EBFC\", show_scalar_bar=False)\n",
    "p.add_title(\"UNet 5dggwboi\", color=\"white\", font_size=26)\n",
    "p.enable_eye_dome_lighting()\n",
    "p.show_axes()\n",
    "p.camera_position = \"iso\"\n",
    "#Prediction 2\n",
    "p.subplot(0, 1)\n",
    "p.add_mesh(contour2, color=\"#FA9017\", show_scalar_bar=False)\n",
    "p.add_title(\"UNet u4lqcs5g\", color=\"white\", font_size=26)\n",
    "p.enable_eye_dome_lighting()\n",
    "p.show_axes()\n",
    "p.camera_position = \"iso\"\n",
    "p.link_views()\n",
    "p.show()\n",
    "\n",
    "#Check mesh stats before export\n",
    "print(f\"contour1: {contour1.n_points} points, {contour1.n_cells} cells\")\n",
    "print(f\"contour2: {contour2.n_points} points, {contour2.n_cells} cells\")\n",
    "# print(f\"spheres: {spheres.n_points} points, {spheres.n_cells} cells\")\n",
    "# print(f\"spheres2: {spheres2.n_points} points, {spheres2.n_cells} cells\")\n",
    "\n",
    "# Export gltf\n",
    "# gltf_path = \"/home/tommytang111/gap-junction-segmentation/html_objects/scene2.gltf\"\n",
    "# p.export_gltf(gltf_path)\n",
    "\n",
    "# # Create minimal HTML wrapper with model-viewer\n",
    "# wrapper_path = \"/home/tommytang111/gap-junction-segmentation/html_objects/scene.html\"\n",
    "# gltf_rel = \"scene.gltf\"\n",
    "# html_wrapper = \"\\n\".join([\n",
    "# \"<!DOCTYPE html><html><head><meta charset='utf-8'><title>Scene</title>\",\n",
    "# \"<script type='module' src='https://ajax.googleapis.com/ajax/libs/model-viewer/3.3.0/model-viewer.min.js'></script>\",\n",
    "# \"<style>\",\n",
    "# \"  html,body{margin:0;height:100%;background:#000;}\",\n",
    "# \"  model-viewer{width:100%;height:100%;}\",\n",
    "# \"</style></head>\",\n",
    "# \"<body>\",\n",
    "# f\"<model-viewer src='{gltf_rel}' camera-controls touch-action='pan-y'\",\n",
    "# \"  shadow-intensity='0' exposure='1.0' environment-image='neutral'\",\n",
    "# \"  ar disable-tap\",\n",
    "# \"  style='background-color:#000000'>\",\n",
    "# \"</model-viewer>\",\n",
    "# \"</body></html>\"\n",
    "# ])\n",
    "# open(wrapper_path, \"w\").write(html_wrapper)\n",
    "# print(\"Wrote:\", wrapper_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59107b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'contour' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m pv\u001b[38;5;241m.\u001b[39mforce_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;32m      6\u001b[0m p \u001b[38;5;241m=\u001b[39m pv\u001b[38;5;241m.\u001b[39mPlotter(notebook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;32m----> 7\u001b[0m p\u001b[38;5;241m.\u001b[39madd_mesh(\u001b[43mcontour\u001b[49m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#02EBFC\u001b[39m\u001b[38;5;124m\"\u001b[39m, opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, show_scalar_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m      8\u001b[0m p\u001b[38;5;241m.\u001b[39madd_mesh(contour2, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#BF35FF\u001b[39m\u001b[38;5;124m\"\u001b[39m, opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, show_scalar_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;32m      9\u001b[0m p\u001b[38;5;241m.\u001b[39madd_mesh(spheres, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#FA9017\u001b[39m\u001b[38;5;124m\"\u001b[39m, show_scalar_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, smooth_shading\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'contour' is not defined"
     ]
    }
   ],
   "source": [
    "#Plotting only combined overlay\n",
    "pv.set_jupyter_backend(\"html\")\n",
    "pv.global_theme.background = 'black'\n",
    "pv.force_float=False\n",
    "\n",
    "p = pv.Plotter(notebook=True)\n",
    "p.add_mesh(contour, color=\"#02EBFC\", opacity=0.5, show_scalar_bar=False)\n",
    "p.add_mesh(contour2, color=\"#BF35FF\", opacity=0.5, show_scalar_bar=False)\n",
    "p.add_mesh(spheres, color=\"#FA9017\", show_scalar_bar=False, smooth_shading=False)\n",
    "p.add_text(\"Prediction + Point Entity + Points Overlay\", position=(0, 0.5), color=\"#02EBFC\", font_size=30)\n",
    "p.enable_eye_dome_lighting()\n",
    "p.show_axes()\n",
    "#p.export_html(\"/home/tommytang111/gap-junction-segmentation/html_objects/SEM_Adult_point_entities_overlay_only.html\")\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a795ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 3D volumes: 100%|██████████| 456/456 [00:04<00:00, 94.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1, 456, (512, 512))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/tommytang111/gap-junction-segmentation/code/src')\n",
    "from utils import create_dataset_3d\n",
    "create_dataset_3d(imgs_dir=\"/home/tommytang111/gap-junction-segmentation/data/sem_adult_larger/SEM_split/imgs\", \n",
    "                  output_dir=\"/home/tommytang111/gap-junction-segmentation/data/972vols_sem_adult/vols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345aca19",
   "metadata": {},
   "source": [
    "### Video Export Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcce1a6",
   "metadata": {},
   "source": [
    "#### Load and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb34b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import numpy as np \n",
    "from skimage.measure import block_reduce\n",
    "import os\n",
    "\n",
    "#Load volumes\n",
    "#pred = np.load(\"/home/tommytang111/gap-junction-segmentation/outputs/volumetric_results/unet_u4lqcs5g/sem_adult_s000-699/volume_block_downsampled4x.npy\")\n",
    "points = np.load(\"/Volumes/Samsung USB/sem_adult_CSs_block_downsampled8x.npy\")\n",
    "points2 = np.load(\"/Volumes/Samsung USB/sem_adult_moved_GJs_downsampled4x.npy\")\n",
    "#point_entities = np.load(\"/home/tommytang111/gap-junction-segmentation/gj_point_annotations/sem_adult_GJs_entities_downsampled8x.npy\")\n",
    "\n",
    "#Block reduce\n",
    "# pred_ = block_reduce(pred, block_size=(1,4,4), func=np.max)\n",
    "points_ = block_reduce(points, block_size=(1,1,1), func=np.max)\n",
    "points2_ = block_reduce(points2, block_size=(1,2,2), func=np.max)\n",
    "#point_entities_ = block_reduce(point_entities, block_size=(1,2,2), func=np.max)\n",
    "\n",
    "#Tranpose to XYZ for pyvista\n",
    "#pred_ = np.transpose(pred_, (2, 1, 0))\n",
    "points_ = np.transpose(points_, (2, 1, 0))\n",
    "points2_ = np.transpose(points2_, (2, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57580421",
   "metadata": {},
   "source": [
    "#### Convert to pyvista objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b148a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2496, 1376, 700)\n",
      "(2496, 1376, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommy/miniconda3/envs/gj/lib/python3.10/site-packages/pyvista/core/utilities/points.py:79: UserWarning: Points is not a float type. This can cause issues when transforming or applying filters. Casting to ``np.float32``. Disable this by passing ``force_float=False``.\n",
      "  warnings.warn(\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1920, 1080) to (1920, 1088) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "#Experimenting with overlaying objects\n",
    "# print(pred_.shape)\n",
    "print(points_.shape)\n",
    "print(points2_.shape)\n",
    "#print(point_entities_.shape)\n",
    "#smaller_pred_3d = pred_3d[:200, 256:768, 256:768]\n",
    "# print(np.unique(pred_3d, return_counts=True))\n",
    "# print(np.unique(smaller_pred_3d, return_counts=True))\n",
    "\n",
    "#Convert to list of points\n",
    "points_list = np.argwhere(points_ == 255)\n",
    "points_list2 = np.argwhere(points2_ == 255)\n",
    "\n",
    "#Transform pred into isosurface\n",
    "# grid = pv.wrap(pred_)\n",
    "# contour = grid.contour(isosurfaces=[255])\n",
    "\n",
    "#Transform point_entities into isosurface\n",
    "# grid2 = pv.wrap(point_entities_)\n",
    "# contour2 = grid2.contour(isosurfaces=[255])\n",
    "\n",
    "#Transform points into glyphs/spheres\n",
    "point_cloud = pv.PolyData(points_list)\n",
    "point_cloud2 = pv.PolyData(points_list2)\n",
    "lowpoly = pv.Sphere(radius=5.0, theta_resolution=8, phi_resolution=8)  # low triangle count\n",
    "spheres = point_cloud.glyph(scale=False, geom=lowpoly, orient=False) #pv.Sphere(radius=2)\n",
    "spheres2 = point_cloud2.glyph(scale=False, geom=lowpoly, orient=False) #pv.Sphere(radius=2)\n",
    "\n",
    "# #Strip all unused data arrays before export and cast from float64 to float32 - reduces export size\n",
    "# for m in (contour, contour2):\n",
    "#     m.clear_data()  # remove point/cell data\n",
    "#     # cast coordinates to float32\n",
    "#     m.points = m.points.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f525d0",
   "metadata": {},
   "source": [
    "#### Export video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31744b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting only combined overlay\n",
    "pv.set_jupyter_backend('client')\n",
    "pv.global_theme.background = 'black'\n",
    "pv.force_float=False\n",
    "\n",
    "p = pv.Plotter(notebook=False, off_screen=True, window_size=[1920, 1080])\n",
    "p.open_movie(\"~/Projects/gap-junction-segmentation/sem_adult_cs_and_gjs.mp4\", framerate=30, quality=8)\n",
    "# p.add_mesh(contour, color=\"#02EBFC\", opacity=0.5, show_scalar_bar=False)\n",
    "# p.add_mesh(contour2, color=\"#BF35FF\", opacity=0.5, show_scalar_bar=False)\n",
    "p.add_mesh(spheres, color=\"#FA9017\", show_scalar_bar=False, smooth_shading=False)\n",
    "p.add_mesh(spheres2, color=\"#02EBFC\", show_scalar_bar=False, smooth_shading=False)\n",
    "p.add_text(\"Chemical and Electrical Synapses\", position=(0, 0), color=\"#FFFFFF\", font_size=24, shadow=True, font=\"courier\")\n",
    "p.enable_eye_dome_lighting()\n",
    "p.camera.zoom(1.2)\n",
    "p.add_camera_orientation_widget()\n",
    "#Scale bar\n",
    "line = np.array([[1000, 650, 380], [1500, 850, 370]])\n",
    "p.add_lines(line, color='w', width=25, connected=True, label=\"100 voxels\")\n",
    "#p.add_scalar_bar()\n",
    "     \n",
    "p.camera_position = [(3868.8407778921764, 292.5636480994484, 40.45188484086728),\n",
    "                     (1349.5000610351562, 727.0, 344.0),\n",
    "                     (-0.18233084170763672, -0.9763841917201768, -0.11588517731410687)]\n",
    "p.show(auto_close=False)\n",
    "\n",
    "#Write frames to video\n",
    "n_frames = 720\n",
    "for _ in range(n_frames): \n",
    "    p.camera.azimuth += 1\n",
    "    #p.reset_camera_clipping_range()  # Keeps the flashing fix\n",
    "    p.write_frame()\n",
    "    \n",
    "p.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
