{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f8f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from utilities import UpBlock, DownBlock, DoubleConv, GenDLoss\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "#Custom Libraries\n",
    "from resize_image import resize_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f50733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seeds\n",
    "def seed_everything(seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    #torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bed85410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Dataset Class\n",
    "#Class can load any mask as long as the model corresponds to the mask type\n",
    "class TrainingDataset(Dataset):\n",
    "    def __init__(self, images, labels, masks=None, augmentation=None, data_size=(512, 512), train=True):\n",
    "        self.image_paths = [os.path.join(images, img) for img in os.listdir(images)]\n",
    "        self.label_paths = [os.path.join(labels, lbl) for lbl in os.listdir(labels)]\n",
    "        self.mask_paths = [os.path.join(masks, mask) for mask in os.listdir(masks)] if masks else None\n",
    "        self.augmentation = augmentation\n",
    "        self.data_size = data_size\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        #Apply resizing with padding if image is not expected size\n",
    "        raw_image = cv2.imread(self.image_paths[idx], cv2.IMREAD_COLOR)\n",
    "        if (raw_image.shape[-1] != self.data_size[0]) or (raw_image.shape[-2] != self.data_size[1]): \n",
    "            raw_image = resize_image(raw_image, self.data_size[0], self.data_size[1], (0,0,0))\n",
    "        \n",
    "        #Read image, label, and mask\n",
    "        image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2GRAY)\n",
    "        label = cv2.imread(self.label_paths[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(self.mask_paths[idx], cv2.IMREAD_GRAYSCALE) if self.mask_paths else None\n",
    "\n",
    "        #Convert mask/label to binary for model classification\n",
    "        label[label > 0] = 1\n",
    "        mask[mask > 0] = 1 if mask is not None else None\n",
    "        \n",
    "        #Add augmentation clause later\n",
    "        #Add entity recognition clause later if needed\n",
    "        \n",
    "        #Convert to tensors\n",
    "        image = ToTensor()(image).float()\n",
    "        label = torch.from_numpy(label).long()\n",
    "        mask = torch.from_numpy(mask).long() if mask is not None else None\n",
    "\n",
    "        return image, label, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a57491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize and load datasets\n",
    "train = TrainingDataset(\n",
    "    images=\"/home/tommytang111/data/sem_adult/SEM_split/s250-259/imgs\",\n",
    "    labels=\"/home/tommytang111/data/sem_adult/SEM_split/s250-259/gts\",\n",
    "    train=True\n",
    ")\n",
    "\n",
    "valid = TrainingDataset(\n",
    "    images=\"/home/tommytang111/data/sem_adult/SEM_split/s200-209/imgs\",\n",
    "    labels=\"/home/tommytang111/data/sem_adult/SEM_split/s200-209/gts\",\n",
    "    train=False\n",
    ")   \n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=8, shuffle=True, num_workers=8, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid, batch_size=8, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fa57f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model and send to gpu\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"UNet Architecture\"\"\"\n",
    "    def __init__(self, out_classes=2, up_sample_mode='conv_transpose', three=False, attend=False, residual=False, scale=False, spatial=False, dropout=0, classes=2):\n",
    "        \"\"\"Initialize the UNet model\"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        self.three = three\n",
    "        self.up_sample_mode = up_sample_mode\n",
    "        self.dropout=dropout\n",
    "\n",
    "        # Downsampling Path\n",
    "        self.down_conv1 = DownBlock(1, 64, three=three, spatial=False, residual=residual) # 3 input channels --> 64 output channels\n",
    "        self.down_conv2 = DownBlock(64, 128, three=three, spatial=spatial, dropout=self.dropout, residual=residual) # 64 input channels --> 128 output channels\n",
    "        self.down_conv3 = DownBlock(128, 256, spatial=spatial, dropout=self.dropout, residual=residual) # 128 input channels --> 256 output channels\n",
    "        self.down_conv4 = DownBlock(256, 512, spatial=spatial, dropout=self.dropout, residual=residual) # 256 input channels --> 512 output channels\n",
    "        # Bottleneck\n",
    "        self.double_conv = DoubleConv(512, 1024,spatial=spatial, dropout=self.dropout, residual=residual)\n",
    "        # Upsampling Path\n",
    "        self.up_conv4 = UpBlock(512 + 1024, 512, self.up_sample_mode, dropout=self.dropout, residual=residual) # 512 + 1024 input channels --> 512 output channels\n",
    "        self.up_conv3 = UpBlock(256 + 512, 256, self.up_sample_mode, dropout=self.dropout, residual=residual)\n",
    "        self.up_conv2 = UpBlock(128+ 256, 128, self.up_sample_mode, dropout=self.dropout, residual=residual)\n",
    "        self.up_conv1 = UpBlock(128 + 64, 64, self.up_sample_mode)\n",
    "        # Final Convolution\n",
    "        self.conv_last = nn.Conv2d(64, 1 if classes == 2 else classes, kernel_size=1)\n",
    "        self.attend = attend\n",
    "        if scale:\n",
    "            self.s1, self.s2 = torch.nn.Parameter(torch.ones(1), requires_grad=True), torch.nn.Parameter(torch.ones(1), requires_grad=True) # learn scaling\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the UNet model\n",
    "        x: (16, 1, 512, 512)\n",
    "        \"\"\"\n",
    "        # print(x.shape)\n",
    "        x, skip1_out = self.down_conv1(x) # x: (16, 64, 256, 256), skip1_out: (16, 64, 512, 512) (batch_size, channels, height, width)    \n",
    "        x, skip2_out = self.down_conv2(x) # x: (16, 128, 128, 128), skip2_out: (16, 128, 256, 256)\n",
    "        if self.three: x = x.squeeze(-3)   \n",
    "        x, skip3_out = self.down_conv3(x) # x: (16, 256, 64, 64), skip3_out: (16, 256, 128, 128)\n",
    "        x, skip4_out = self.down_conv4(x) # x: (16, 512, 32, 32), skip4_out: (16, 512, 64, 64)\n",
    "        x = self.double_conv(x) # x: (16, 1024, 32, 32)\n",
    "        x = self.up_conv4(x, skip4_out) # x: (16, 512, 64, 64)\n",
    "        x = self.up_conv3(x, skip3_out) # x: (16, 256, 128, 128)\n",
    "        if self.three: \n",
    "            #attention_mode???\n",
    "            skip1_out = torch.mean(skip1_out, dim=2)\n",
    "            skip2_out = torch.mean(skip2_out, dim=2)\n",
    "        x = self.up_conv2(x, skip2_out) # x: (16, 128, 256, 256)\n",
    "        x = self.up_conv1(x, skip1_out) # x: (16, 64, 512, 512)\n",
    "        x = self.conv_last(x) # x: (16, 1, 512, 512)\n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\")    \n",
    "model = UNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf895300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize loss function and optimizer\n",
    "loss_fn = GenDLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gap_junction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
