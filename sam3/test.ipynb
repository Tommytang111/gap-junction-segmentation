{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29499f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1917c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-time setup: ensure Transformers supports SAM3\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(*args: str) -> None:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\", *args])\n",
    "\n",
    "# If this still errors with model_type sam3_video, install from source:\n",
    "# pip_install(\"git+https://github.com/huggingface/transformers.git\")\n",
    "pip_install(\"pip\")\n",
    "pip_install(\"transformers\", \"accelerate\", \"safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a3a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path(\"/Users/tommy/Projects/gap-junction-segmentation/data/sem_adult_imgs_test\")\n",
    "OUT_DIR = Path(\"/Users/tommy/Projects/gap-junction-segmentation/outputs/sam3_masks\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "image_paths = sorted(DATA_DIR.glob(\"*.png\"))\n",
    "len(image_paths), image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAM3 mask-generation pipeline\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"mask-generation\",\n",
    "    model=\"facebook/sam3\",\n",
    "    trust_remote_code=True,\n",
    "    device=device,\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d1b577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90ccd7a0ef8462ba752fde1583fbe1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f87a29ed034e0c8c4aa0888256dcd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/685 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e346c66013945bca010fff4e8ba7c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processor_config.json:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2d1b6d080a4b91814af90697548c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e98867c39a40729cd2cfd555de9f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95443071750448aba22acb5a2cc4db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb9c9878d4a40178623a639ba300f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da7a732bfaa47ccaa3c6260c3d5ff15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/588 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7b249f0301416190f1855596927d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/1797 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run SAM3 on a single image (sanity check)\n",
    "img_path = image_paths[0]\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "output = pipe(img)\n",
    "\n",
    "def extract_masks(output, height: int, width: int) -> np.ndarray:\n",
    "    \"\"\"Returns boolean masks with shape (N, H, W).\"\"\"\n",
    "    if isinstance(output, dict):\n",
    "        masks_obj = output.get(\"masks\", None)\n",
    "        if masks_obj is None and \"mask\" in output:\n",
    "            masks_obj = [output[\"mask\"]]\n",
    "    elif isinstance(output, list):\n",
    "        # Some pipelines return a list of dicts with a 'mask' entry\n",
    "        if len(output) == 0:\n",
    "            return np.zeros((0, height, width), dtype=bool)\n",
    "        if isinstance(output[0], dict) and \"mask\" in output[0]:\n",
    "            masks_obj = [o[\"mask\"] for o in output]\n",
    "        else:\n",
    "            masks_obj = output\n",
    "    else:\n",
    "        masks_obj = None\n",
    "\n",
    "    if masks_obj is None:\n",
    "        raise ValueError(f\"Unexpected pipeline output type/format: {type(output)}\")\n",
    "\n",
    "    # Normalize to a stacked numpy array\n",
    "    if isinstance(masks_obj, torch.Tensor):\n",
    "        masks = masks_obj.detach().cpu().numpy()\n",
    "    elif isinstance(masks_obj, np.ndarray):\n",
    "        masks = masks_obj\n",
    "    else:\n",
    "        masks_list = []\n",
    "        for m in masks_obj:\n",
    "            if isinstance(m, torch.Tensor):\n",
    "                m = m.detach().cpu().numpy()\n",
    "            elif not isinstance(m, np.ndarray):\n",
    "                m = np.array(m)\n",
    "            masks_list.append(m)\n",
    "        masks = np.stack(masks_list, axis=0) if len(masks_list) else np.zeros((0, height, width), dtype=bool)\n",
    "\n",
    "    # Force shape (N, H, W) and bool dtype\n",
    "    if masks.ndim == 2:\n",
    "        masks = masks[None, :, :]\n",
    "    masks = masks.astype(bool)\n",
    "    return masks\n",
    "\n",
    "def erode3x3(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Binary erosion with a 3x3 square structuring element (no SciPy).\"\"\"\n",
    "    h, w = mask.shape\n",
    "    p = np.pad(mask, 1, mode=\"constant\", constant_values=False)\n",
    "    out = np.ones((h, w), dtype=bool)\n",
    "    for dy in range(3):\n",
    "        for dx in range(3):\n",
    "            out &= p[dy : dy + h, dx : dx + w]\n",
    "    return out\n",
    "\n",
    "masks = extract_masks(output, img.height, img.width)\n",
    "print(f\"{img_path.name}: {masks.shape[0]} masks, size {masks.shape[-2:]}\" )\n",
    "\n",
    "# Union mask (foreground)\n",
    "union_bool = np.any(masks, axis=0)\n",
    "union = union_bool.astype(np.uint8) * 255\n",
    "union_path = OUT_DIR / f\"{img_path.stem}_union.png\"\n",
    "Image.fromarray(union).save(union_path)\n",
    "\n",
    "# Membrane-like boundary from union mask\n",
    "membrane_bool = union_bool & (~erode3x3(union_bool))\n",
    "membrane = membrane_bool.astype(np.uint8) * 255\n",
    "membrane_path = OUT_DIR / f\"{img_path.stem}_membrane.png\"\n",
    "Image.fromarray(membrane).save(membrane_path)\n",
    "\n",
    "union_path, membrane_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ea287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch run: save union + membrane boundary masks per image\n",
    "for img_path in image_paths:\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    output = pipe(img)\n",
    "    masks = extract_masks(output, img.height, img.width)\n",
    "\n",
    "    union_bool = np.any(masks, axis=0)\n",
    "    union = union_bool.astype(np.uint8) * 255\n",
    "    Image.fromarray(union).save(OUT_DIR / f\"{img_path.stem}_union.png\")\n",
    "\n",
    "    membrane_bool = union_bool & (~erode3x3(union_bool))\n",
    "    membrane = membrane_bool.astype(np.uint8) * 255\n",
    "    Image.fromarray(membrane).save(OUT_DIR / f\"{img_path.stem}_membrane.png\")\n",
    "\n",
    "print(f\"Saved {len(image_paths)} union+membrane masks to {OUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
